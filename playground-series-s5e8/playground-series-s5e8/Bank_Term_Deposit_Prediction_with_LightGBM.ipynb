{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Starting the Bank Term Deposit Prediction script (Enhanced Version)...\")\n",
        "\n",
        "# --- 1. Load Data ---\n",
        "# This assumes you have uploaded 'train.csv', 'test.csv', and 'sample_submission.csv'\n",
        "# to your Google Colab environment.\n",
        "try:\n",
        "    train_df = pd.read_csv('train.csv')\n",
        "    test_df = pd.read_csv('test.csv')\n",
        "    sample_submission_df = pd.read_csv('sample_submission.csv')\n",
        "    print(\"Data loaded successfully: train.csv, test.csv, sample_submission.csv\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: One or more of the required CSV files (train.csv, test.csv, sample_submission.csv) were not found.\")\n",
        "    print(\"Please ensure these files are uploaded to your Colab environment or the correct path is provided.\")\n",
        "    # It's good practice to exit or raise an error if critical files are missing\n",
        "    exit()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQqP301EXsGl",
        "outputId": "424a9193-f34c-4323-d1f0-686e7e848e3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting the Bank Term Deposit Prediction script (Enhanced Version)...\n",
            "Data loaded successfully: train.csv, test.csv, sample_submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Preprocessing and Feature Engineering ---\n",
        "\n",
        "# Store test IDs for the final submission file\n",
        "test_ids = test_df['id']\n",
        "\n",
        "# Drop the 'id' column from both training and test dataframes as it's not a predictive feature\n",
        "train_df = train_df.drop('id', axis=1)\n",
        "test_df = test_df.drop('id', axis=1)\n",
        "\n",
        "# Separate features (X) and target (y) from the training data\n",
        "X = train_df.drop('y', axis=1)\n",
        "y = train_df['y']\n",
        "X_test = test_df.copy() # Create a copy for the test features\n",
        "\n",
        "print(\"Starting enhanced feature engineering...\")\n",
        "\n",
        "# --- Feature Engineering ---\n",
        "\n",
        "# 2.1 Handle 'pdays' feature\n",
        "# Create a binary feature indicating if the client was previously contacted\n",
        "X['pdays_contacted'] = (X['pdays'] != -1).astype(int)\n",
        "X_test['pdays_contacted'] = (X_test['pdays'] != -1).astype(int)\n",
        "\n",
        "# Replace -1 in pdays with 0 (or another appropriate value) before transformation\n",
        "# This signifies no previous contact for the duration aspect\n",
        "X['pdays'] = X['pdays'].replace(-1, 0)\n",
        "X_test['pdays'] = X_test['pdays'].replace(-1, 0)\n",
        "\n",
        "# Apply log1p transformation to pdays to reduce skewness\n",
        "X['pdays'] = np.log1p(X['pdays'])\n",
        "X_test['pdays'] = np.log1p(X_test['pdays'])\n",
        "\n",
        "# 2.2 Numerical Feature Transformations and Outlier Handling\n",
        "# Apply log1p transformation to 'duration'\n",
        "# Note: In a real-world scenario, 'duration' would not be known at prediction time.\n",
        "# However, for Kaggle competitions, it's a powerful feature.\n",
        "X['duration'] = np.log1p(X['duration'])\n",
        "X_test['duration'] = np.log1p(X_test['duration'])\n",
        "\n",
        "# Cap 'campaign' at its 99th percentile to handle outliers\n",
        "campaign_cap = X['campaign'].quantile(0.99)\n",
        "X['campaign'] = X['campaign'].clip(upper=campaign_cap)\n",
        "X_test['campaign'] = X_test['campaign'].clip(upper=campaign_cap)\n",
        "\n",
        "# Apply log1p transformation to 'balance' after shifting to handle negative values\n",
        "min_balance_train = X['balance'].min()\n",
        "min_balance_test = X_test['balance'].min()\n",
        "shift_constant = abs(min(min_balance_train, min_balance_test)) + 1 # Add 1 to avoid log(0)\n",
        "\n",
        "X['balance'] = np.log1p(X['balance'] + shift_constant)\n",
        "X_test['balance'] = np.log1p(X_test['balance'] + shift_constant)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXxddwspkGkA",
        "outputId": "4032380e-9ab5-4cef-f5bb-07c764b5841f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting enhanced feature engineering...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.3 Create Interaction Features\n",
        "# Ratio of balance to age (handle age being 0, though unlikely)\n",
        "X['balance_age_ratio'] = X['balance'] / (X['age'] + 1e-6)\n",
        "X_test['balance_age_ratio'] = X_test['balance'] / (X_test['age'] + 1e-6)\n",
        "\n",
        "# Ratio of duration to campaign (handle campaign being 0)\n",
        "X['duration_per_campaign'] = X['duration'] / (X['campaign'] + 1e-6)\n",
        "X_test['duration_per_campaign'] = X_test['duration'] / (X_test['campaign'] + 1e-6)\n",
        "\n",
        "# Interaction between balance and duration\n",
        "X['balance_duration_interaction'] = X['balance'] * X['duration']\n",
        "X_test['balance_duration_interaction'] = X_test['balance'] * X_test['duration']\n",
        "\n",
        "# Interaction between age and duration\n",
        "X['age_duration_interaction'] = X['age'] * X['duration']\n",
        "X_test['age_duration_interaction'] = X_test['age'] * X_test['duration']\n",
        "\n",
        "# 2.4 Handle 'month' feature - convert to numerical\n",
        "month_map = {\n",
        "    'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6,\n",
        "    'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12\n",
        "}\n",
        "X['month'] = X['month'].map(month_map)\n",
        "X_test['month'] = X_test['month'].map(month_map)\n",
        "\n",
        "\n",
        "# Identify categorical features for one-hot encoding (after numerical month conversion)\n",
        "categorical_features = [\n",
        "    'job', 'marital', 'education', 'default', 'housing',\n",
        "    'loan', 'contact', 'poutcome' # 'month' is now numerical\n",
        "]\n",
        "\n",
        "# Apply One-Hot Encoding to categorical features for both training and test sets\n",
        "X = pd.get_dummies(X, columns=categorical_features, drop_first=True)\n",
        "X_test = pd.get_dummies(X_test, columns=categorical_features, drop_first=True)\n",
        "\n",
        "# Align columns between training and test sets after all feature engineering\n",
        "train_cols = X.columns\n",
        "test_cols = X_test.columns\n",
        "\n",
        "# Add missing columns to the test set and fill with zeros\n",
        "missing_in_test = set(train_cols) - set(test_cols)\n",
        "for c in missing_in_test:\n",
        "    X_test[c] = 0\n",
        "\n",
        "# Add missing columns to the training set and fill with zeros (less common, but good practice)\n",
        "missing_in_train = set(test_cols) - set(train_cols)\n",
        "for c in missing_in_train:\n",
        "    X[c] = 0\n",
        "\n",
        "# Ensure the columns are in the same order for both X and X_test\n",
        "X_test = X_test[train_cols]\n",
        "\n",
        "print(f\"Enhanced feature engineering complete. Training features shape: {X.shape}, Test features shape: {X_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZX9a3OgkKsI",
        "outputId": "ab329b5a-1c1e-4fbd-c2d9-0e4035fd8c97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enhanced feature engineering complete. Training features shape: (750000, 37), Test features shape: (250000, 37)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Model Training with Stratified K-Fold Cross-Validation ---\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "NFOLDS = 5\n",
        "# Initialize StratifiedKFold to preserve the percentage of samples for each class\n",
        "folds = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "# Arrays to store out-of-fold predictions and submission predictions\n",
        "oof_preds = np.zeros(X.shape[0])\n",
        "sub_preds = np.zeros(X_test.shape[0])\n",
        "\n",
        "print(f\"Starting model training with {NFOLDS}-Fold Stratified Cross-Validation...\")\n",
        "\n",
        "# LightGBM model parameters (tuned for potentially better performance)\n",
        "lgb_params = {\n",
        "    'objective': 'binary',\n",
        "    'metric': 'auc',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'n_estimators': 3000,         # Increased estimators\n",
        "    'learning_rate': 0.005,       # Decreased learning rate\n",
        "    'num_leaves': 31,             # Slightly increased leaves\n",
        "    'max_depth': 7,               # Slightly increased max depth\n",
        "    'seed': 42,\n",
        "    'n_jobs': -1,\n",
        "    'verbose': -1,\n",
        "    'colsample_bytree': 0.7,\n",
        "    'subsample': 0.7,\n",
        "    'reg_alpha': 0.1,\n",
        "    'reg_lambda': 0.1,\n",
        "    'min_child_samples': 20,      # Minimum number of data needed in a child (leaf)\n",
        "}\n",
        "\n",
        "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(X, y)):\n",
        "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
        "    X_valid, y_valid = X.iloc[valid_idx], y.iloc[valid_idx]\n",
        "\n",
        "    model = lgb.LGBMClassifier(**lgb_params)\n",
        "\n",
        "    model.fit(X_train, y_train,\n",
        "              eval_set=[(X_valid, y_valid)],\n",
        "              eval_metric='auc',\n",
        "              callbacks=[lgb.early_stopping(200, verbose=False)]) # Increased early stopping rounds\n",
        "\n",
        "    oof_preds[valid_idx] = model.predict_proba(X_valid)[:, 1]\n",
        "    sub_preds += model.predict_proba(X_test)[:, 1] / folds.n_splits\n",
        "\n",
        "    print(f\"Fold {n_fold+1}/{NFOLDS} completed. Validation AUC: {roc_auc_score(y_valid, oof_preds[valid_idx]):.4f}\")\n",
        "\n",
        "# Calculate the overall Out-Of-Fold AUC score\n",
        "overall_oof_auc = roc_auc_score(y, oof_preds)\n",
        "print(f\"\\nOverall Out-Of-Fold AUC Score: {overall_oof_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsBxIUw0j9U8",
        "outputId": "2cd85524-bce6-4e05-e50a-96a27bfc4c70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting model training with 5-Fold Stratified Cross-Validation...\n",
            "Fold 1/5 completed. Validation AUC: 0.9656\n",
            "Fold 2/5 completed. Validation AUC: 0.9643\n",
            "Fold 3/5 completed. Validation AUC: 0.9647\n",
            "Fold 4/5 completed. Validation AUC: 0.9657\n",
            "Fold 5/5 completed. Validation AUC: 0.9650\n",
            "\n",
            "Overall Out-Of-Fold AUC Score: 0.9651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Create Submission File ---\n",
        "\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': test_ids,\n",
        "    'y': sub_preds\n",
        "})\n",
        "\n",
        "# Save the submission file to your Colab environment\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "\n",
        "print(\"\\n--- Script Execution Complete ---\")\n",
        "print(f\"Final submission file 'submission.csv' created successfully with {len(submission_df)} predictions.\")\n",
        "print(\"You can now download 'submission.csv' from the left-hand file panel in Colab and submit it to Kaggle.\")\n",
        "print(\"This enhanced version should provide a better score. Good luck!\")\n"
      ],
      "metadata": {
        "id": "VlwC8oRmjiJ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2814cec-c8d4-4d3e-94b1-127b516c9542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Script Execution Complete ---\n",
            "Final submission file 'submission.csv' created successfully with 250000 predictions.\n",
            "You can now download 'submission.csv' from the left-hand file panel in Colab and submit it to Kaggle.\n",
            "This enhanced version should provide a better score. Good luck!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}